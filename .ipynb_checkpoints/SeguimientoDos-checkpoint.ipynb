{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0b8d2f1-07fb-4050-8b9c-ac8d5e9854ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import os\n",
    "import importlib.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7998aeb8-0038-47ce-b464-5590abd20dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_archivo = r\"C:\\seguimiento_dos\\claves.txt\"\n",
    "\n",
    "# Verificar si el archivo existe\n",
    "if os.path.exists(ruta_archivo):\n",
    "    with open(ruta_archivo, \"r\") as archivo:\n",
    "        lineas = archivo.readlines()\n",
    "\n",
    "    # Crear un diccionario para almacenar las claves y valores\n",
    "    claves = {}\n",
    "    for linea in lineas:\n",
    "        # Ignorar líneas vacías y comentarios (si los hubiera)\n",
    "        if linea.strip() and \"=\" in linea:\n",
    "            clave, valor = linea.strip().split(\"=\", 1)\n",
    "            claves[clave.strip()] = valor.strip()\n",
    "\n",
    "    # Asignar cada valor a una variable\n",
    "    correo = claves.get(\"Correo\")\n",
    "    password = claves.get(\"Password\")\n",
    "    rutaDescarga = claves.get(\"rutaDescarga\")\n",
    "    rutaConsolidado = claves.get(\"rutaConsolidado\")\n",
    "    rutaModificacionConsolidado = claves.get(\"rutaModificacionConsolidado\")\n",
    "    rutaDuplicados = claves.get(\"rutaDuplicados\")\n",
    "    rutaTiempos = claves.get(\"rutaTiempos\")\n",
    "    rutaOrdenamiento = claves.get(\"rutaOrdenamiento\")\n",
    "    rutaEstadisticas= claves.get(\"rutaEstadisticas\")\n",
    "    baseIEEE = claves.get(\"archivoBaseIEEE\");\n",
    "    baseSage = claves.get(\"archivoBaseSage\");\n",
    "    baseScience = claves.get(\"archivoBaseScience\");\n",
    "    binaryInsertionsort_path = claves.get(\"binaryInsertionsort\");\n",
    "    bitonicsort_path = claves.get(\"bitonicsort\");\n",
    "    bubblesort_path = claves.get(\"bubblesort\");\n",
    "    bucketsort_path = claves.get(\"bucketsort\");\n",
    "    combsort_path = claves.get(\"combsort\");\n",
    "    gnomesort_path = claves.get(\"gnomesort\");\n",
    "    heapsort_path = claves.get(\"heapsort\");\n",
    "    pigeonholesort_path = claves.get(\"pigeonholesort\");\n",
    "    quicksort_path = claves.get(\"quicksort\");\n",
    "    radixsort_path = claves.get(\"radixsort\");\n",
    "    selectionsort_path = claves.get(\"selectionsort\");\n",
    "    timsort_path = claves.get(\"timsort\");\n",
    "    treesort_path = claves.get(\"treesort\");\n",
    "else:\n",
    "    print(f\"El archivo {ruta_archivo} no existe.\")\n",
    "    exit()\n",
    "\n",
    "def import_algorithm(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"El archivo {file_path} no existe.\")\n",
    "        return None\n",
    "    \n",
    "    module_name = os.path.basename(file_path).split('.')[0]\n",
    "    spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    \n",
    "    # Asumimos que cada módulo tiene una función principal con el mismo nombre\n",
    "    if hasattr(module, module_name):\n",
    "        return getattr(module, module_name)\n",
    "    else:\n",
    "        print(f\"No se encontró la función {module_name} en el archivo {file_path}\")\n",
    "        return None\n",
    "\n",
    "# Configurar la ruta de descarga (usando una ruta absoluta)\n",
    "download_path = rutaDescarga  # Cambia esto a tu ruta real\n",
    "os.makedirs(download_path, exist_ok=True)  # Crear la carpeta si no existe\n",
    "\n",
    "# Configurar opciones de Chrome específicas para  descargas automáticas\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "\n",
    "\n",
    "# Configuración de preferencias de descargas\n",
    "prefs = {\n",
    "    \"download.default_directory\": download_path,\n",
    "    \"download.prompt_for_download\": False,\n",
    "    \"download.directory_upgrade\": True,\n",
    "    \"safebrowsing.enabled\": False,  # Desactivar SafeBrowsing puede ayudar\n",
    "    \"profile.default_content_settings.popups\": 0,\n",
    "    \"profile.content_settings.exceptions.automatic_downloads.*.setting\": 1\n",
    "}\n",
    "chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "# Argumentos adicionales que pueden ayudar\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "chrome_options.add_argument(\"--disable-download-notification\")\n",
    "chrome_options.add_argument(\"--disable-popup-blocking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd7589f7-6c0a-40dc-a578-7684dbd2dc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Botón presionado exitosamente\n",
      "Se cerró la ventana de cookies.\n",
      "⚠ No apareció la ventana de cookies o ya estaba cerrada.\n",
      "Procesando página 1 de 11...\n",
      "Intento de descarga #1 para página 1\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #2 para página 1\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #3 para página 1\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #4 para página 1\n",
      "✅ Descarga exitosa para página 1: IEEE Xplore Citation BibTeX Download 2025.4.6.10.51.20.bib\n",
      "Error al renombrar archivo: [WinError 183] No se puede crear un archivo que ya existe: 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\IEEE Xplore Citation BibTeX Download 2025.4.6.10.51.20.bib' -> 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\computational_thinking_page_1.bib'\n",
      "🔄 Avanzando a la página 2...\n",
      "Procesando página 2 de 11...\n",
      "Intento de descarga #1 para página 2\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #2 para página 2\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #3 para página 2\n",
      "✅ Descarga exitosa para página 2: IEEE Xplore Citation BibTeX Download 2025.4.6.10.52.25.bib\n",
      "Error al renombrar archivo: [WinError 183] No se puede crear un archivo que ya existe: 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\IEEE Xplore Citation BibTeX Download 2025.4.6.10.52.25.bib' -> 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\computational_thinking_page_2.bib'\n",
      "🔄 Avanzando a la página 3...\n",
      "Procesando página 3 de 11...\n",
      "Intento de descarga #1 para página 3\n",
      "✅ Descarga exitosa para página 3: IEEE Xplore Citation BibTeX Download 2025.4.6.10.52.48.bib\n",
      "Error al renombrar archivo: [WinError 183] No se puede crear un archivo que ya existe: 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\IEEE Xplore Citation BibTeX Download 2025.4.6.10.52.48.bib' -> 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\computational_thinking_page_3.bib'\n",
      "🔄 Avanzando a la página 4...\n",
      "Procesando página 4 de 11...\n",
      "Intento de descarga #1 para página 4\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #2 para página 4\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #3 para página 4\n",
      "✅ Descarga exitosa para página 4: IEEE Xplore Citation BibTeX Download 2025.4.6.10.53.52.bib\n",
      "Error al renombrar archivo: [WinError 183] No se puede crear un archivo que ya existe: 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\IEEE Xplore Citation BibTeX Download 2025.4.6.10.53.52.bib' -> 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\computational_thinking_page_4.bib'\n",
      "🔄 Avanzando a la página 5...\n",
      "Procesando página 5 de 11...\n",
      "Intento de descarga #1 para página 5\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #2 para página 5\n",
      "✅ Descarga exitosa para página 5: IEEE Xplore Citation BibTeX Download 2025.4.6.10.54.37.bib\n",
      "Error al renombrar archivo: [WinError 183] No se puede crear un archivo que ya existe: 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\IEEE Xplore Citation BibTeX Download 2025.4.6.10.54.37.bib' -> 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\computational_thinking_page_5.bib'\n",
      "🔄 Avanzando a la página 6...\n",
      "Procesando página 6 de 11...\n",
      "Intento de descarga #1 para página 6\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #2 para página 6\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #3 para página 6\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #4 para página 6\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #5 para página 6\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #6 para página 6\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #7 para página 6\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #8 para página 6\n",
      "✅ Descarga exitosa para página 6: IEEE Xplore Citation BibTeX Download 2025.4.6.10.57.22.bib\n",
      "Error al renombrar archivo: [WinError 183] No se puede crear un archivo que ya existe: 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\IEEE Xplore Citation BibTeX Download 2025.4.6.10.57.22.bib' -> 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\computational_thinking_page_6.bib'\n",
      "🔄 Avanzando a la página 7...\n",
      "Procesando página 7 de 11...\n",
      "Intento de descarga #1 para página 7\n",
      "✅ Descarga exitosa para página 7: IEEE Xplore Citation BibTeX Download 2025.4.6.10.57.46.bib\n",
      "Error al renombrar archivo: [WinError 183] No se puede crear un archivo que ya existe: 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\IEEE Xplore Citation BibTeX Download 2025.4.6.10.57.46.bib' -> 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\computational_thinking_page_7.bib'\n",
      "🔄 Avanzando a la página 8...\n",
      "Procesando página 8 de 11...\n",
      "Intento de descarga #1 para página 8\n",
      "✅ Descarga exitosa para página 8: IEEE Xplore Citation BibTeX Download 2025.4.6.10.58.10.bib\n",
      "Error al renombrar archivo: [WinError 183] No se puede crear un archivo que ya existe: 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\IEEE Xplore Citation BibTeX Download 2025.4.6.10.58.10.bib' -> 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\computational_thinking_page_8.bib'\n",
      "🔄 Avanzando a la página 9...\n",
      "Procesando página 9 de 11...\n",
      "Intento de descarga #1 para página 9\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #2 para página 9\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #3 para página 9\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #4 para página 9\n",
      "✅ Descarga exitosa para página 9: IEEE Xplore Citation BibTeX Download 2025.4.6.10.59.34.bib\n",
      "Error al renombrar archivo: [WinError 183] No se puede crear un archivo que ya existe: 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\IEEE Xplore Citation BibTeX Download 2025.4.6.10.59.34.bib' -> 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\computational_thinking_page_9.bib'\n",
      "🔄 Avanzando a la página 10...\n",
      "Procesando página 10 de 11...\n",
      "Intento de descarga #1 para página 10\n",
      "✅ Descarga exitosa para página 10: IEEE Xplore Citation BibTeX Download 2025.4.6.10.59.59.bib\n",
      "Error al renombrar archivo: [WinError 183] No se puede crear un archivo que ya existe: 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\IEEE Xplore Citation BibTeX Download 2025.4.6.10.59.59.bib' -> 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\computational_thinking_page_10.bib'\n",
      "🔄 Avanzando a la página 11...\n",
      "Procesando página 11 de 11...\n",
      "Intento de descarga #1 para página 11\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #2 para página 11\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #3 para página 11\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #4 para página 11\n",
      "⚠️ Tiempo de espera de descarga agotado.\n",
      "Intento de descarga #5 para página 11\n",
      "✅ Descarga exitosa para página 11: IEEE Xplore Citation BibTeX Download 2025.4.6.11.1.43.bib\n",
      "Error al renombrar archivo: [WinError 183] No se puede crear un archivo que ya existe: 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\IEEE Xplore Citation BibTeX Download 2025.4.6.11.1.43.bib' -> 'C:\\\\Users\\\\Orlay Molina\\\\Documents\\\\Workspace\\\\algoritmos\\\\seguimiento_dos\\\\carpeta_descarga\\\\computational_thinking_page_11.bib'\n",
      "¡Proceso completado! Se han intentado descargar los datos de las 11 páginas.\n"
     ]
    }
   ],
   "source": [
    "%run \"{baseIEEE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6c0cb83-c189-46d4-82e1-67571cf313ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Botón presionado exitosamente\n",
      "Se cerró la ventana de cookies.\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\n\tGetHandleVerifier [0x00007FF61E9A4C25+3179557]\n\t(No symbol) [0x00007FF61E6088A0]\n\t(No symbol) [0x00007FF61E4991CA]\n\t(No symbol) [0x00007FF61E4EFA67]\n\t(No symbol) [0x00007FF61E4EFC9C]\n\t(No symbol) [0x00007FF61E543627]\n\t(No symbol) [0x00007FF61E517C6F]\n\t(No symbol) [0x00007FF61E5402F3]\n\t(No symbol) [0x00007FF61E517A03]\n\t(No symbol) [0x00007FF61E4E06D0]\n\t(No symbol) [0x00007FF61E4E1983]\n\tGetHandleVerifier [0x00007FF61EA067CD+3579853]\n\tGetHandleVerifier [0x00007FF61EA1D1D2+3672530]\n\tGetHandleVerifier [0x00007FF61EA12153+3627347]\n\tGetHandleVerifier [0x00007FF61E77092A+868650]\n\t(No symbol) [0x00007FF61E612FFF]\n\t(No symbol) [0x00007FF61E60F4A4]\n\t(No symbol) [0x00007FF61E60F646]\n\t(No symbol) [0x00007FF61E5FEAA9]\n\tBaseThreadInitThunk [0x00007FFDBCC17374+20]\n\tRtlUserThreadStart [0x00007FFDBD8FCC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutException\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_7716\\546062047.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Esperar a que la barra de búsqueda esté en el DOM\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m barra_busquedaSage = \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mEC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpresence_of_element_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/html/body/div[2]/div/div/div[1]/main/div/div[1]/section/div/div/div/div/div/div/div/div[2]/div/div/div/form/div/input\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\selenium\\webdriver\\support\\wait.py:146\u001b[39m, in \u001b[36mWebDriverWait.until\u001b[39m\u001b[34m(self, method, message)\u001b[39m\n\u001b[32m    144\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    145\u001b[39m     time.sleep(\u001b[38;5;28mself\u001b[39m._poll)\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[31mTimeoutException\u001b[39m: Message: \nStacktrace:\n\tGetHandleVerifier [0x00007FF61E9A4C25+3179557]\n\t(No symbol) [0x00007FF61E6088A0]\n\t(No symbol) [0x00007FF61E4991CA]\n\t(No symbol) [0x00007FF61E4EFA67]\n\t(No symbol) [0x00007FF61E4EFC9C]\n\t(No symbol) [0x00007FF61E543627]\n\t(No symbol) [0x00007FF61E517C6F]\n\t(No symbol) [0x00007FF61E5402F3]\n\t(No symbol) [0x00007FF61E517A03]\n\t(No symbol) [0x00007FF61E4E06D0]\n\t(No symbol) [0x00007FF61E4E1983]\n\tGetHandleVerifier [0x00007FF61EA067CD+3579853]\n\tGetHandleVerifier [0x00007FF61EA1D1D2+3672530]\n\tGetHandleVerifier [0x00007FF61EA12153+3627347]\n\tGetHandleVerifier [0x00007FF61E77092A+868650]\n\t(No symbol) [0x00007FF61E612FFF]\n\t(No symbol) [0x00007FF61E60F4A4]\n\t(No symbol) [0x00007FF61E60F646]\n\t(No symbol) [0x00007FF61E5FEAA9]\n\tBaseThreadInitThunk [0x00007FFDBCC17374+20]\n\tRtlUserThreadStart [0x00007FFDBD8FCC91+33]\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\n\tGetHandleVerifier [0x00007FF61E9A4C25+3179557]\n\t(No symbol) [0x00007FF61E6088A0]\n\t(No symbol) [0x00007FF61E4991CA]\n\t(No symbol) [0x00007FF61E4EFA67]\n\t(No symbol) [0x00007FF61E4EFC9C]\n\t(No symbol) [0x00007FF61E543627]\n\t(No symbol) [0x00007FF61E517C6F]\n\t(No symbol) [0x00007FF61E5402F3]\n\t(No symbol) [0x00007FF61E517A03]\n\t(No symbol) [0x00007FF61E4E06D0]\n\t(No symbol) [0x00007FF61E4E1983]\n\tGetHandleVerifier [0x00007FF61EA067CD+3579853]\n\tGetHandleVerifier [0x00007FF61EA1D1D2+3672530]\n\tGetHandleVerifier [0x00007FF61EA12153+3627347]\n\tGetHandleVerifier [0x00007FF61E77092A+868650]\n\t(No symbol) [0x00007FF61E612FFF]\n\t(No symbol) [0x00007FF61E60F4A4]\n\t(No symbol) [0x00007FF61E60F646]\n\t(No symbol) [0x00007FF61E5FEAA9]\n\tBaseThreadInitThunk [0x00007FFDBCC17374+20]\n\tRtlUserThreadStart [0x00007FFDBD8FCC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutException\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrun\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{baseSage}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:2481\u001b[39m, in \u001b[36mInteractiveShell.run_line_magic\u001b[39m\u001b[34m(self, magic_name, line, _stack_depth)\u001b[39m\n\u001b[32m   2479\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mlocal_ns\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.get_local_scope(stack_depth)\n\u001b[32m   2480\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m-> \u001b[39m\u001b[32m2481\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2483\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2484\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2485\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2486\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\magics\\execution.py:748\u001b[39m, in \u001b[36mExecutionMagics.run\u001b[39m\u001b[34m(self, parameter_s, runner, file_finder)\u001b[39m\n\u001b[32m    746\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m preserve_keys(\u001b[38;5;28mself\u001b[39m.shell.user_ns, \u001b[33m'\u001b[39m\u001b[33m__file__\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    747\u001b[39m         \u001b[38;5;28mself\u001b[39m.shell.user_ns[\u001b[33m'\u001b[39m\u001b[33m__file__\u001b[39m\u001b[33m'\u001b[39m] = filename\n\u001b[32m--> \u001b[39m\u001b[32m748\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshell\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_execfile_ipy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    751\u001b[39m \u001b[38;5;66;03m# Control the response to exit() calls made by the script being run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:2972\u001b[39m, in \u001b[36mInteractiveShell.safe_execfile_ipy\u001b[39m\u001b[34m(self, fname, shell_futures, raise_exceptions)\u001b[39m\n\u001b[32m   2970\u001b[39m result = \u001b[38;5;28mself\u001b[39m.run_cell(cell, silent=\u001b[38;5;28;01mTrue\u001b[39;00m, shell_futures=shell_futures)\n\u001b[32m   2971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m raise_exceptions:\n\u001b[32m-> \u001b[39m\u001b[32m2972\u001b[39m     \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2973\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result.success:\n\u001b[32m   2974\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:309\u001b[39m, in \u001b[36mExecutionResult.raise_error\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    307\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m.error_before_exec\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.error_in_exec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m.error_in_exec\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_7716\\546062047.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Esperar a que la barra de búsqueda esté en el DOM\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m barra_busquedaSage = \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mEC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpresence_of_element_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/html/body/div[2]/div/div/div[1]/main/div/div[1]/section/div/div/div/div/div/div/div/div[2]/div/div/div/form/div/input\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\selenium\\webdriver\\support\\wait.py:146\u001b[39m, in \u001b[36mWebDriverWait.until\u001b[39m\u001b[34m(self, method, message)\u001b[39m\n\u001b[32m    144\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    145\u001b[39m     time.sleep(\u001b[38;5;28mself\u001b[39m._poll)\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[31mTimeoutException\u001b[39m: Message: \nStacktrace:\n\tGetHandleVerifier [0x00007FF61E9A4C25+3179557]\n\t(No symbol) [0x00007FF61E6088A0]\n\t(No symbol) [0x00007FF61E4991CA]\n\t(No symbol) [0x00007FF61E4EFA67]\n\t(No symbol) [0x00007FF61E4EFC9C]\n\t(No symbol) [0x00007FF61E543627]\n\t(No symbol) [0x00007FF61E517C6F]\n\t(No symbol) [0x00007FF61E5402F3]\n\t(No symbol) [0x00007FF61E517A03]\n\t(No symbol) [0x00007FF61E4E06D0]\n\t(No symbol) [0x00007FF61E4E1983]\n\tGetHandleVerifier [0x00007FF61EA067CD+3579853]\n\tGetHandleVerifier [0x00007FF61EA1D1D2+3672530]\n\tGetHandleVerifier [0x00007FF61EA12153+3627347]\n\tGetHandleVerifier [0x00007FF61E77092A+868650]\n\t(No symbol) [0x00007FF61E612FFF]\n\t(No symbol) [0x00007FF61E60F4A4]\n\t(No symbol) [0x00007FF61E60F646]\n\t(No symbol) [0x00007FF61E5FEAA9]\n\tBaseThreadInitThunk [0x00007FFDBCC17374+20]\n\tRtlUserThreadStart [0x00007FFDBD8FCC91+33]\n"
     ]
    }
   ],
   "source": [
    "%run \"{baseSage}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f9f05-f684-4e52-825f-a42273df63c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"{baseScience}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c62593-5627-459c-9436-98c4cf15604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def remove_doi_line_from_bibtex(input_text):\n",
    "    # Patrón para encontrar entradas BibTeX\n",
    "    entries_pattern = r'(@\\w+\\{[^,]+,)\\s*doi:[^,]+,([\\s\\S]*?(?=@|\\Z))'\n",
    "    \n",
    "    # Reemplazar con la primera línea y el resto del contenido, excluyendo la línea DOI\n",
    "    cleaned_text = re.sub(entries_pattern, r'\\1\\2', input_text)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "def add_missing_keys_from_bibtex(input_text):\n",
    "    def add_missing_keys_to_entry(entry):\n",
    "        lines_to_add = []\n",
    "        # Verifica si falta la clave publisher (sin distinguir mayúsculas)\n",
    "        if not re.search(r'\\bpublisher\\s*=', entry, re.IGNORECASE):\n",
    "            lines_to_add.append('publisher = {},')\n",
    "        # # Verifica si falta la clave journal\n",
    "        # if not re.search(r'\\bjournal\\s*=', entry, re.IGNORECASE):\n",
    "        #     lines_to_add.append('journal = {},')\n",
    "        \n",
    "        if lines_to_add:\n",
    "            # Se ubica la posición de la llave de cierre \"}\" de la entrada\n",
    "            pos = entry.rfind(\"}\")\n",
    "            if pos != -1:\n",
    "                before = entry[:pos].rstrip()\n",
    "                # Asegurarse de que la última línea termine con coma\n",
    "                if not before.endswith(\",\"):\n",
    "                    before += \",\"\n",
    "                # Inserta las líneas con las claves faltantes antes de la llave de cierre\n",
    "                entry = before + \"\\n\" + \"\\n\".join(lines_to_add) + \"\\n\" + entry[pos:]\n",
    "        return entry\n",
    "\n",
    "    # Patrón para capturar cada entrada BibTeX (se asume que la entrada termina en una línea que contiene \"}\")\n",
    "    pattern = r'(@\\w+\\s*\\{[\\s\\S]*?\\}\\s*)(?=@|$)'\n",
    "    entries = re.findall(pattern, input_text, flags=re.DOTALL)\n",
    "    \n",
    "    for entry in entries:\n",
    "        new_entry = add_missing_keys_to_entry(entry)\n",
    "        input_text = input_text.replace(entry, new_entry)\n",
    "    return input_text\n",
    "\n",
    "def process_bibtex_files(directory_path, output_directory=None):\n",
    "    # Crear directorio de salida si no existe\n",
    "    if output_directory and not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    \n",
    "    bibtex_files = glob.glob(os.path.join(directory_path, \"*.bib\")) + \\\n",
    "                   glob.glob(os.path.join(directory_path, \"*.bibtex\"))\n",
    "    \n",
    "    for file_path in bibtex_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        print(f\"Procesando {filename}...\")\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # Primero elimina la línea DOI\n",
    "        modified_content = remove_doi_line_from_bibtex(content)\n",
    "        # Luego agrega las claves faltantes publisher y journal\n",
    "        modified_content = add_missing_keys_from_bibtex(modified_content)\n",
    "        \n",
    "        if output_directory:\n",
    "            output_path = os.path.join(output_directory, filename)\n",
    "        else:\n",
    "            output_path = file_path\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(modified_content)\n",
    "        \n",
    "        print(f\"✅ Archivo procesado y guardado como {output_path}\")\n",
    "    \n",
    "    print(f\"\\nTotal de archivos procesados: {len(bibtex_files)}\")\n",
    "\n",
    "def process_single_bibtex_file(file_path, output_path=None):\n",
    "    if output_path is None:\n",
    "        output_path = file_path\n",
    "    \n",
    "    print(f\"Procesando {os.path.basename(file_path)}...\")\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    modified_content = remove_doi_line_from_bibtex(content)\n",
    "    modified_content = add_missing_keys_from_bibtex(modified_content)\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(modified_content)\n",
    "    \n",
    "    print(f\"✅ Archivo procesado y guardado como {output_path}\")\n",
    "\n",
    "# Ejemplo de uso para procesar un directorio\n",
    "process_bibtex_files(rutaDescarga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d979a9f-30eb-4ed3-acc7-16e6987bc5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c470a4e9-42f7-427f-9a61-d2e1593e27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import tempfile\n",
    "import shutil\n",
    "import re\n",
    "from pybtex.database.input import bibtex as bibtex_input\n",
    "from pybtex.database.output import bibtex as bibtex_output\n",
    "from pybtex.database import BibliographyData\n",
    "from natsort import natsorted\n",
    "\n",
    "def process_bibtex_file_with_clean_environment(file_path):\n",
    "    \"\"\"Procesa un archivo BibTeX con un entorno limpio para evitar problemas de caché.\"\"\"\n",
    "    # Crear directorio temporal\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    try:\n",
    "        # Copiar el archivo a un directorio temporal con un nombre único\n",
    "        temp_file = os.path.join(temp_dir, f\"temp_{os.path.basename(file_path)}\")\n",
    "        shutil.copy2(file_path, temp_file)\n",
    "        \n",
    "        # Usar un nuevo parser para cada archivo\n",
    "        parser = bibtex_input.Parser()\n",
    "        bib_data = parser.parse_file(temp_file)\n",
    "        \n",
    "        return bib_data\n",
    "    finally:\n",
    "        # Limpiar el directorio temporal\n",
    "        shutil.rmtree(temp_dir)\n",
    "\n",
    "def normalize_title(title):\n",
    "    \"\"\"Normaliza un título para facilitar la comparación.\n",
    "    Elimina espacios extra, signos de puntuación y convierte a minúsculas.\"\"\"\n",
    "    if not title:\n",
    "        return \"\"\n",
    "    # Eliminar caracteres especiales y convertir a minúsculas\n",
    "    normalized = re.sub(r'[^\\w\\s]', '', title.lower())\n",
    "    # Eliminar espacios múltiples y convertir a minúsculas\n",
    "    normalized = re.sub(r'\\s+', ' ', normalized).strip().lower()\n",
    "    return normalized\n",
    "\n",
    "def merge_bibtex_files(file_paths, output_path, DUPLICATES_PATH):\n",
    "    merged_db = BibliographyData()\n",
    "    duplicates_list = []\n",
    "    processed_titles = {}  # Cambiado de processed_ids a processed_titles\n",
    "    duplicate_entries = set()  # Para contar entradas duplicadas únicas\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            print(f\"\\nProcesando: {file_path}\")\n",
    "            bib_data = process_bibtex_file_with_clean_environment(file_path)\n",
    "\n",
    "            for entry_id, entry in bib_data.entries.items():\n",
    "                # Verificar si el entry tiene un campo de título\n",
    "                if 'title' not in entry.fields:\n",
    "                    print(f\"  Advertencia: Entrada {entry_id} sin título en {file_path}, se agregará como única\")\n",
    "                    merged_db.add_entry(entry_id, entry)\n",
    "                    continue\n",
    "                \n",
    "                # Normalizar el título para comparación\n",
    "                title = entry.fields['title']\n",
    "                normalized_title = normalize_title(title)\n",
    "                \n",
    "                if normalized_title in processed_titles:\n",
    "                    # Encontramos un título duplicado\n",
    "                    original_entry_id, original_file = processed_titles[normalized_title]\n",
    "                    print(f\"  Duplicado encontrado por título: {title}\")\n",
    "                    print(f\"  Original ID: {original_entry_id} en: {original_file}\")\n",
    "                    print(f\"  Duplicado ID: {entry_id} en: {file_path}\")\n",
    "                    \n",
    "                    # Agregar el ID a la lista de duplicados únicos\n",
    "                    duplicate_entries.add(entry_id)\n",
    "\n",
    "                    # Guardar duplicado como texto en la lista\n",
    "                    duplicates_list.append(f\"@{entry.type}{{{entry_id},\\n\")\n",
    "                    duplicates_list.append(f\"  title = {{{title}}},\\n\")\n",
    "                    for field, value in entry.fields.items():\n",
    "                        if field != 'title':  # Ya agregamos el título\n",
    "                            duplicates_list.append(f\"  {field} = {{{value}}},\\n\")\n",
    "                    duplicates_list.append(\"}\\n\\n\")\n",
    "                    \n",
    "                else:\n",
    "                    # Es un título nuevo, lo agregamos\n",
    "                    merged_db.add_entry(entry_id, entry)\n",
    "                    processed_titles[normalized_title] = (entry_id, file_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar {file_path}: {e}\")\n",
    "\n",
    "    # Guardar el archivo consolidado\n",
    "    writer = bibtex_output.Writer()\n",
    "    writer.write_file(merged_db, output_path)\n",
    "    print(f\"Archivo consolidado guardado en: {output_path}\")\n",
    "\n",
    "    # Guardar el archivo de duplicados manualmente\n",
    "    if duplicates_list:\n",
    "        with open(DUPLICATES_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.writelines(duplicates_list)\n",
    "        print(f\"Duplicados guardados en: {DUPLICATES_PATH}\")\n",
    "    else:\n",
    "        print(\"No se encontraron duplicados.\")\n",
    "    \n",
    "    return len(merged_db.entries), len(duplicate_entries)\n",
    "\n",
    "def main():\n",
    "    folder_path = rutaDescarga\n",
    "\n",
    "    # Obtenemos los archivos .bib sin la ruta completa\n",
    "    files_in_folder = [f for f in os.listdir(folder_path) if f.endswith('.bib')]\n",
    "    \n",
    "    # Ordenamos usando natsorted para lograr un \"orden natural\"\n",
    "    files_in_folder = natsorted(files_in_folder)\n",
    "\n",
    "    # Verificar en que orden se procesaran los archivos\n",
    "    print(\"Orden de procesamiento de archivos:\")\n",
    "    for i, f in enumerate(files_in_folder):\n",
    "        print(f\"{i+1}. {f}\")\n",
    "\n",
    "    # Construimos las rutas completas\n",
    "    bibtex_files = [os.path.join(folder_path, f) for f in files_in_folder]\n",
    "\n",
    "    # Verificar que los archivos sean únicos\n",
    "    print(\"\\nVerificando unicidad de archivos...\")\n",
    "    file_hashes = {}\n",
    "    unique_files = []\n",
    "    \n",
    "    for file_path in bibtex_files:\n",
    "        # Calcular hash del archivo\n",
    "        file_hash = hashlib.md5()\n",
    "        with open(file_path, 'rb') as f:\n",
    "            for chunk in iter(lambda: f.read(4096), b''):\n",
    "                file_hash.update(chunk)\n",
    "        \n",
    "        # Verificar si ya hemos visto este hash\n",
    "        digest = file_hash.hexdigest()\n",
    "        if digest in file_hashes:\n",
    "            print(f\"¡ADVERTENCIA! Archivo duplicado detectado:\")\n",
    "            print(f\"  - {file_path}\")\n",
    "            print(f\"  - {file_hashes[digest]}\")\n",
    "            print(f\"  Ambos tienen el mismo hash: {digest}\")\n",
    "        else:\n",
    "            file_hashes[digest] = file_path\n",
    "            unique_files.append(file_path)\n",
    "    \n",
    "    print(f\"Total de archivos encontrados: {len(bibtex_files)}\")\n",
    "    print(f\"Archivos únicos por contenido: {len(unique_files)}\")\n",
    "    \n",
    "    # Proceder solo con archivos únicos\n",
    "    bibtex_files = unique_files\n",
    "\n",
    "    # Rutas para archivos de salida\n",
    "    output_path = os.path.join(rutaConsolidado, \"consolidado.bib\")\n",
    "    DUPLICATES_PATH = os.path.join(rutaDuplicados, \"duplicados.bib\")\n",
    "    \n",
    "    unique_count, duplicate_count = merge_bibtex_files(bibtex_files, output_path, DUPLICATES_PATH)\n",
    "    \n",
    "    print(f\"\\nResumen:\")\n",
    "    print(f\"  Archivos procesados: {len(bibtex_files)}\")\n",
    "    print(f\"  Entradas únicas: {unique_count}\")\n",
    "    print(f\"  Entradas duplicadas: {duplicate_count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e412a7-7cf4-4030-b946-e8546745ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def remove_fields_from_bibtex(input_text):\n",
    "    # Lista de campos a eliminar con sus posibles variantes (con y sin espacio)\n",
    "    fields_to_remove = [\n",
    "        r'number\\s*=\\s*\\{[^}]*\\},?\\s*',\n",
    "        r'pages\\s*=\\s*\\{[^}]*\\},?\\s*',\n",
    "        r'volume\\s*=\\s*\\{[^}]*\\},?\\s*',\n",
    "        r'issn\\s*=\\s*\\{[^}]*\\},?\\s*',\n",
    "        r'ISSN\\s*=\\s*\\{[^}]*\\},?\\s*',\n",
    "        r'eprint\\s*=\\s*\\{[^}]*\\},?\\s*',\n",
    "        r'url\\s*=\\s*\\{[^}]*\\},?\\s*',\n",
    "        r'URL\\s*=\\s*\\{[^}]*\\},?\\s*',\n",
    "        r'month\\s*=\\s*\\{[^}]*\\},?\\s*',\n",
    "        r'editor\\s*=\\s*\\{[^}]*\\},?\\s*',\n",
    "        r'series\\s*=\\s*\\{[^}]*\\},?\\s*',\n",
    "        r'isbn\\s*=\\s*\\{[^}]*\\},?\\s*',\n",
    "        r'address\\s*=\\s*\\{[^}]*\\},?\\s*',\n",
    "        r'note\\s*=\\s*\\{[^}]*\\},?\\s*',\n",
    "        r'edition\\s*=\\s*\\{[^}]*\\},?\\s*',\n",
    "        # También manejar casos donde el valor no está entre llaves\n",
    "        r'number\\s*=\\s*\"[^\"]*\",?\\s*',\n",
    "        r'pages\\s*=\\s*\"[^\"]*\",?\\s*',\n",
    "        r'volume\\s*=\\s*\"[^\"]*\",?\\s*',\n",
    "        r'issn\\s*=\\s*\"[^\"]*\",?\\s*',\n",
    "        r'ISSN\\s*=\\s*\"[^\"]*\",?\\s*',\n",
    "        r'eprint\\s*=\\s*\"[^\"]*\",?\\s*',\n",
    "        r'url\\s*=\\s*\"[^\"]*\",?\\s*',\n",
    "        r'URL\\s*=\\s*\"[^\"]*\",?\\s*',\n",
    "        r'month\\s*=\\s*\"[^\"]*\",?\\s*',\n",
    "        r'editor\\s*=\\s*\"[^\"]*\",?\\s*',\n",
    "        r'series\\s*=\\s*\"[^\"]*\",?\\s*',\n",
    "        r'isbn\\s*=\\s*\"[^\"]*\",?\\s*',\n",
    "        r'address\\s*=\\s*\"[^\"]*\",?\\s*',\n",
    "        r'note\\s*=\\s*\"[^\"]*\",?\\s*',\n",
    "        r'edition\\s*=\\s*\"[^\"]*\",?\\s*',\n",
    "        # Manejar casos donde el valor es numérico sin comillas\n",
    "        r'number\\s*=\\s*\\d+,?\\s*',\n",
    "        r'pages\\s*=\\s*\\d+,?\\s*',\n",
    "        r'volume\\s*=\\s*\\d+,?\\s*',\n",
    "        r'month\\s*=\\s*\\d+,?\\s*',\n",
    "        r'editor\\s*=\\s*\\d+,?\\s*',\n",
    "        r'series\\s*=\\s*\\d+,?\\s*',\n",
    "        r'isbn\\s*=\\s*\\d+,?\\s*',\n",
    "        r'address\\s*=\\s*\\d+,?\\s*',\n",
    "        r'note\\s*=\\s*\\d+,?\\s*',\n",
    "        r'edition\\s*=\\s*\\d+,?\\s*',\n",
    "        # Manejar casos donde el valor está entre llaves especiales\n",
    "        r'url\\s*=\\s*\\[\\[[^]]*\\]\\],?\\s*',\n",
    "        r'URL\\s*=\\s*\\[\\[[^]]*\\]\\],?\\s*',\n",
    "    ]\n",
    "    \n",
    "    # Procesamos cada entrada BibTeX\n",
    "    modified_text = input_text\n",
    "    \n",
    "    # Aplicamos cada patrón de eliminación\n",
    "    for pattern in fields_to_remove:\n",
    "        modified_text = re.sub(pattern, '', modified_text)\n",
    "    \n",
    "    return modified_text\n",
    "\n",
    "def process_bibtex_files(directory_path, output_directory=None):\n",
    "    # Crear directorio de salida si no existe\n",
    "    if output_directory and not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    \n",
    "    # Buscar todos los archivos BibTeX\n",
    "    bibtex_files = glob.glob(os.path.join(directory_path, \"*.bib\")) + \\\n",
    "                   glob.glob(os.path.join(directory_path, \"*.bibtex\"))\n",
    "    \n",
    "    for file_path in bibtex_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        print(f\"Procesando {filename}...\")\n",
    "        \n",
    "        # Leer el archivo\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # Eliminar campos específicos\n",
    "        modified_content = remove_fields_from_bibtex(content)\n",
    "        \n",
    "        # Determinar ruta de salida\n",
    "        if output_directory:\n",
    "            output_path = os.path.join(output_directory, filename)\n",
    "        else:\n",
    "            output_path = file_path\n",
    "        \n",
    "        # Guardar el archivo modificado\n",
    "        with open(output_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(modified_content)\n",
    "        \n",
    "        print(f\"✅ Archivo procesado y guardado como {output_path}\")\n",
    "    \n",
    "    print(f\"\\nTotal de archivos procesados: {len(bibtex_files)}\")\n",
    "\n",
    "# Ejemplo de uso para procesar un directorio\n",
    "#process_bibtex_files(rutaDescarga)\n",
    "\n",
    "# Ejemplo para procesar un solo archivo\n",
    "def process_single_bibtex_file(file_path, output_path=None):\n",
    "    \n",
    "    if output_path is None:\n",
    "        output_path = file_path\n",
    "    \n",
    "    print(f\"Procesando {os.path.basename(file_path)}...\")\n",
    "    \n",
    "    # Leer el archivo\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Eliminar campos específicos\n",
    "    modified_content = remove_fields_from_bibtex(content)\n",
    "    \n",
    "    # Guardar el archivo modificado\n",
    "    with open(output_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(modified_content)\n",
    "    \n",
    "    print(f\"✅ Archivo procesado y guardado como {output_path}\")\n",
    "\n",
    "process_single_bibtex_file(rutaModificacionConsolidado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8bec0-89f6-4913-9705-ba0f527d794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import heapq\n",
    "from functools import cmp_to_key\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import bisect\n",
    "\n",
    "# Definir rutas\n",
    "BIBTEX_PATH = rutaModificacionConsolidado\n",
    "OUTPUT_PATH = rutaOrdenamiento\n",
    "TIMING_PATH = rutaTiempos\n",
    "\n",
    "# Crear directorios si no existen\n",
    "Path(OUTPUT_PATH).mkdir(parents=True, exist_ok=True)\n",
    "Path(TIMING_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# %%\n",
    "def extract_bibtex_fields(file_path):\n",
    "    fields = {\n",
    "        'author': [],\n",
    "        'title': [],\n",
    "        'journal': [],\n",
    "        'year': [],\n",
    "        'doi': [],\n",
    "        'keywords': [],\n",
    "        'abstract': [],\n",
    "        'publisher': [],  # Añadido campo publisher\n",
    "        'entry_type': []  # Campo para el tipo de entrada\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Buscar entradas BibTeX (cualquier tipo: article, inproceedings, etc.)\n",
    "        entries = re.findall(r'@\\w+\\s*\\{[^@]*\\}', content, re.DOTALL)\n",
    "        \n",
    "        for entry in entries:\n",
    "            # Extraer el tipo de entrada\n",
    "            entry_type_match = re.match(r'@(\\w+)', entry, re.IGNORECASE)\n",
    "            entry_type = entry_type_match.group(1) if entry_type_match else \"unknown\"\n",
    "            fields['entry_type'].append(entry_type)\n",
    "            \n",
    "            for field in [k for k in fields.keys() if k != 'entry_type']:\n",
    "                # Buscar el campo en la entrada, manejando {valor} o \"valor\"\n",
    "                pattern = rf'{field}\\s*=\\s*[\\{{\\\"](.*?)[\\}}\\\"]'\n",
    "                match = re.search(pattern, entry, re.IGNORECASE | re.DOTALL)\n",
    "                \n",
    "                # Para journal, buscar booktitle si no se encontró journal\n",
    "                if field == 'journal' and not match:\n",
    "                    pattern = r'booktitle\\s*=\\s*[\\{{\\\"](.*?)[\\}}\\\"]'\n",
    "                    match = re.search(pattern, entry, re.IGNORECASE | re.DOTALL)\n",
    "                \n",
    "                if match:\n",
    "                    value = match.group(1).strip()\n",
    "                    fields[field].append(value)\n",
    "                else:\n",
    "                    fields[field].append(\"\")\n",
    "        \n",
    "        return fields\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar el archivo BibTeX: {e}\")\n",
    "        return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "032c7f8c-3a29-4998-98a1-8bdfd99387ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'import_algorithm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Importar las funciones de los algoritmos\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m algo_name, algo_path \u001b[38;5;129;01min\u001b[39;00m algorithm_paths.items():\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     algorithms[algo_name] = \u001b[43mimport_algorithm\u001b[49m(algo_path)\n",
      "\u001b[31mNameError\u001b[39m: name 'import_algorithm' is not defined"
     ]
    }
   ],
   "source": [
    "algorithms = {}\n",
    "algorithm_paths = {\n",
    "    'timsort': timsort,\n",
    "    'combsort': combsort,\n",
    "    'selectionsort': selectionsort,\n",
    "    'treesort': treesort,\n",
    "    'pigeonholesort': pigeonholesort,\n",
    "    'bucketsort': bucketsort,\n",
    "    'binaryInsertionsort': binaryInsertionsort,\n",
    "    'bitonicsort': bitonicsort,\n",
    "    'bubblesort': bubblesort,\n",
    "    'quicksort': quicksort,\n",
    "    'heapsort': heapsort,\n",
    "    'gnomesort': gnomesort,\n",
    "    'radixsort': radixsort\n",
    "}\n",
    "\n",
    "# Importar las funciones de los algoritmos\n",
    "for algo_name, algo_path in algorithm_paths.items():\n",
    "    algorithms[algo_name] = import_algorithm(algo_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478fa328-d695-47e1-b709-bb8149eab685",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = extract_bibtex_fields(BIBTEX_PATH)\n",
    "\n",
    "# Diccionarios para almacenar resultados ordenados y tiempos\n",
    "sorted_results = { key: {} for key in fields.keys() }\n",
    "timings = { key: {} for key in fields.keys() }\n",
    "\n",
    "# Para cada campo, aplicar cada algoritmo y medir el tiempo de ejecución\n",
    "for field, values in fields.items():\n",
    "    for algo_name, algo_func in algorithms.items():\n",
    "        if algo_func is None:\n",
    "            continue\n",
    "            \n",
    "        start_time = time.time()\n",
    "        sorted_list = algo_func(values.copy())  # Usamos una copia para no modificar el original\n",
    "        end_time = time.time()\n",
    "        elapsed = (end_time - start_time)\n",
    "        sorted_results[field][algo_name] = sorted_list\n",
    "        timings[field][algo_name] = elapsed\n",
    "\n",
    "# Escribir archivos de salida para cada clave en OUTPUT_PATH\n",
    "for field, algo_results in sorted_results.items():\n",
    "    file_path = os.path.join(OUTPUT_PATH, f\"{field}.txt\")\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        for algo_name in algorithms.keys():\n",
    "            f.write(f\"# ordenamiento por {algo_name}\\n\")\n",
    "            for item in algo_results[algo_name]:\n",
    "                f.write(item + \"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "# Escribir archivo con tiempos de ordenamiento en TIMING_PATH\n",
    "timing_file = os.path.join(TIMING_PATH, \"tiempo-ordenamiento.txt\")\n",
    "with open(timing_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"Campo,Algoritmo,Tiempo (segundos)\\n\")\n",
    "    for field, algo_times in timings.items():\n",
    "        for algo_name, t in algo_times.items():\n",
    "            f.write(f\"{field},{algo_name},{t}\\n\")\n",
    "\n",
    "# Graficar tiempos de ordenamiento para cada clave\n",
    "for field, algo_times in timings.items():\n",
    "    if not algo_times:\n",
    "        continue\n",
    "        \n",
    "    algo_names = list(algo_times.keys())\n",
    "    times_list = [algo_times[algo] for algo in algo_names]\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.bar(algo_names, times_list)\n",
    "    plt.xlabel('Algoritmo')\n",
    "    plt.ylabel('Tiempo (segundos)')\n",
    "    plt.title(f'Tiempos de ordenamiento para el campo: {field}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    # Guardar la gráfica en TIMING_PATH (por ejemplo, \"tiempo_author.png\")\n",
    "    plt.savefig(os.path.join(TIMING_PATH, f\"tiempo_{field}.png\"))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
